\documentclass{kluwer}    % Specifies the document style.

\newdisplay{guess}{Conjecture}

\begin{document}                                                                                   
\begin{article}
\begin{opening}         
\title{Expected Dependency Pair Match:\\
Predicting improvements to {HTER} with expected syntactic structure} 
\author{Jeremy G. \surname{Kahn}\email{jgk@u.washington.edu}}  
\institute{University of Washington}
\author{Matthew \surname{Snover}\email{snover@cs.umd.edu}}
\institute{University of Maryland}
\author{Mari \surname{Ostendorf}\email{ostendor@u.washington.edu}}  
\institute{University of Washington}
\runningauthor{Kahn, Snover \& Ostendorf}
\runningtitle{Expected Dependency Pair Match}
\date{May 10, 2009}

\begin{abstract}
Abstract to go here
\end{abstract}
\keywords{machine translation evaluation, syntax, dependency trees}

\end{opening}           

\section{Introduction}

\begin{itemize}
\item evaluation [esp. automatic evaluation]
\item popular current
  measures BLEU, TER

\item challenges - motivate search for better measures

\item other extensions:
  \begin{itemize}
  \item METEOR 
    \begin{itemize}
    \item stemming and synonym tables
    \item tuned but not generally     tuneable
    \end{itemize}
  \item TERp
    \begin{itemize}
    \item development-set tuning by user
    \item stemming and synonym tables
    \item paraphrase tables
    \end{itemize}
  \end{itemize}
\item prior work with (partial) syntactic locality:
  \begin{itemize}
  \item Liu \& Gildea 
  \item Roark et al. Sparseval
  \item Owczarzak et al. 2007
  \end{itemize}


\item Evaluation of evaluation measures
  \begin{itemize}
  \item correlation vs. human fluency/adequacy 
  \item correlation vs. human-in-the-loop measures (HTER)
  \end{itemize}
\item one challenge of metric-evaluation: underlying doc difficulty 
  \begin{itemize}
  \item describe mean-subtraction
  \end{itemize}
\end{itemize}

\section{Experimental paradigm}

Section explains space of measures to explore

\begin{itemize}
\item F-measure over various bags of components of parse tree

  [ Figure describing Sparseval-ish variant ]

\item Listing possible component valences
  \begin{itemize}
  \item dependent + labeled link + head 
  \item outbound only (dependent +
    label)
  \item inbound only (label + head)
  \item word-word (skipping label)
  \end{itemize}
  \begin{itemize}
  \item 1-grams
  \item 2-grams
  \item \ldots{}
  \end{itemize}
  
  Note: inbound links \& full pairs "overweight" head words; this is
  a good thing.

  [ figure demonstrating F-measure over d+l+h decomposition of toy
  trees ]
    
\item Tree features may be extracted from a 1-best tree, or from an
  n-best tree list 

  \begin{itemize}
  \item  counts are an expectation over the forest
  \item n parameter: how many trees in the forest
  \item gamma parameter for flattening overconfident parse hyps
  \end{itemize}
  note intentional similarities to Owczarzak paper


\item Components in the basic DPM measures combined in various ways:

  \begin{itemize}
  \item combination of precision, recall scores for different
    components (on analogy with BLEU combination), naive assumption:
    all weighted equally

  \item simple F over items of all valences (naive assumption: all
    weighted equally)
  \end{itemize}
\item Tuneable weights:
  \begin{itemize}
  \item recall that TERp has tuneable system over small number of parameters
    \begin{itemize}
    \item insertion weight
    \item deletion weight
    \item substitution weight
    \item synonym weight (motivated with WordNet)
    \end{itemize}
  \item learn weights for separate precision, recall for various
    components
  \end{itemize}
  
\item Implementation
  \begin{itemize}
  \item Charniak parser
  \item n=1..50
  \item head-finding, with some modifications
  \item label-construction
  \end{itemize}
\end{itemize}

\section{Correlation with human judgments of fluency \& adequacy}

Corpus: LDC Multiple Translation Chinese corpus 3\&4 treat each
segment and each judgment as independent data point

\begin{itemize}
\item EXPT

  using n=1 parse for DPM variants

\begin{verbatim}
   metric      r
  --------   -----
  F[dl;lh]   0.226
  BLEU4      0.218  # +1 smoothing
  F[dlh]     0.185
  TER       -0.173
\end{verbatim}

  point: using partial-labeling (dl,lh) much better than full
  link. Also, using Charniak parser as labeler seems to work, LFG not
  necessary

\item EXPT 

  combining precision, recall naively vs. combining items

\begin{verbatim}
  F(1g,2g,dl,lh)        0.237
  prmeans(1g,2g,dl,lh)  0.217

  F(dl,lh)              0.226
  prmeans(dl,lh)        0.208
\end{verbatim}

  point: combining individual items naively (before computing
  precision and recall) seems better than naively combining precisions
  and recalls (too many chances for zeroes?)

\item EXPT
  expanding n, gamma=0

\begin{verbatim}
  F[1g,2g,dl,lh],n=50   0.239
    ...          n=1    0.237
  F[dl,lh],n=50         0.234
    ...    n=1          0.226
\end{verbatim}
  point: larger n $\to$ better r
  (holds for other comparisons too, but these are good examples)

\item  EXPT

  setting gamma

  Tuning experiments finds that gamma of 0.25 is slightly better
  (especially when using F[dl,lh]) than gammas of other values in
  range 0-1 (these values probably not significant)

\end{itemize}

\section{Correlations with HTER}

  Corpus
    Gale translation corpus 2.5; 3 sites, 2 source languages, 4 genres each

  prediction:
    Mean-subtracted HTER per-document

  base measure EDPM: F[1g,2g,dl,lh],n=50,gamma=0.25

  [EXPT]
\begin{verbatim}
            Ar     Zh    All
   TER     0.51   0.32  0.44
   BLEU_4 -0.42  -0.33 -0.37
   EDPM   -0.60* -0.39 -0.50*
\end{verbatim}
  point: base EDPM does better on all docs, and on Arabic. difference
  is not quite significant at the p=0.05 on the Chinese documents

  Note 1: also tried pairwise deltas per-document, with similar
  results, as presented in the MetricsMATR competition submission.

  Note 2: when using per-segment mean-subtracted, r values are smaller
  and *Arabic* was the language where EDPM did not perform best.

\begin{verbatim}
               Ar     Zh     All
      TER     0.38*  0.04   0.19
      BLEU_4 -0.10  -0.16  -0.14
      EDPM   -0.31  -0.19* -0.24*
\end{verbatim}

  (Go into details of per-genre differences here? or leave out, for
  space reasons? -- leave out, I'd say)

\section{Weight-tuning to combine syntax and other knowledge sources}

TERp optimizer [Matt, a brief description here]

TERp comes with a variety of features (described earlier)

include optionally new features

Corpus: GALE 2.5 data, again documents randomly split into two groups,
evenly split across language and genre

tuning target: weighted correlation with mean-removed segment HTER

[we use weighted correlation to avoid emphasis on short segments
(which hurts document-level and system-level utility) ]

Select features from set:

\begin{description}
\item[E]: features from EDPM, specifically, P,R for inbound, outbound,
  full-links, and unlabeled links  (8 features)
\item[T]: features from basic TERp
  (inserts, deletes, substitutions, shifts)  (7 features)
\item[P]: features from TERp paraphraser
  (4 features)
\item[N]: precision and recall for 1-grams, 2-grams
\item[B]: brevity/prolixity (2 features: one for longer-than-ref, one for
  shorter-than-ref)
\end{description}

tune weights on one set, test on the other (and vice versa).
reporting average r between the two.

\begin{verbatim}
   == Tuned For Weighted Mean Removed Pearson
     - Examining WGT_MEAN_RM_SEG_PEAR ==
            Average
      Cond   Test  
     ---------------
      ETPB   0.4096
      ETP    0.4038
      TPB    0.4010
      TP     0.3946
      TPNB   0.3940
      TPN    0.3891
      ETB    0.3871
      ET     0.3827
      TB     0.3815
      ETNB   0.3814
      ETN    0.3804
      T      0.3758
      TNB    0.3708
      TN     0.3680
      E      0.3287
      EB     0.3267
      ENB    0.3149
      NB     0.3058
      EN     0.2973
      N      0.2636
      B      0.1638
\end{verbatim}
(maybe don't report all these numbers!)
  
point: E+T $>$ T, E+TB $>$ TB, E+TP $>$ TP; information is available in
syntax that is not captured in the other measures.

point: syntax is *not* just an expensive way to get at n-grams;
N-grams are not the same -- TP $>$ TP+N, but TP $<$ TP+E

\section{Conclusion}

expected dependency pair matching gets at something new

troubling area: speed of analysis -- current implementation requires
running a complete n-best parser

possible use: as a late-pass evaluation, to identify how systems
perform overall

future work:  explore ways to get at syntactic information without
the expense of a full parser:
\begin{itemize}
\item this work moves from an LFG parser (Owczarzak) to the
  substantially simpler and more robust Charniak system - keep going
  and look at simpler partial-parsing approaches (forests?)
\item conversely: how important is it that the parses be of
  high-quality?
\end{itemize}

\section{References in the THEBIBLIOGRAPHY Environment}
The first reference in the list below has the key \{BrownAndBurton\}.
Together with the bibitem option $\backslash$citeauthoryear\{Brown and
Burton\}\{1978\} the follwing cross-references can be used:\\
$\backslash$cite\{BrownAndBurton\} produces: \cite{BrownAndBurton}\\
$\backslash$shortcite\{BrownAndBurton\}  produces: \shortcite{BrownAndBurton}\\  
$\backslash$citeauthor\{BrownAndBurton\}  produces: \citeauthor{BrownAndBurton}\\  
$\backslash$citeyear\{BrownAndBurton\}  produces: \citeyear{BrownAndBurton}\\  


\appendix

And this is my Appendix.


\acknowledgements
And this is an acknowledgements section with a heading that was produced by the
$\backslash$acknowledgements command. Thank you all for helping me writing this
\LaTeX\ sample file.

% The endnotes section will be placed here.

\theendnotes

\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Brown and Burton}{1978}]{BrownAndBurton}
J.~S. Brown and R.~R. Burton.
\newblock {Diagnostic Models for Procedural Bugs in Basic Mathematical Skills}.
\newblock {\em Cognitive Science}, 2(2):155--192, 1978.

\bibitem[\protect\citeauthoryear{Buchanan}{1984}]{BuchananRBES}
Bruce~G. Buchanan and Edward~H. Shortliffe.
\newblock {\em Rule-Based Expert Systems: The MYCIN Experiments of the Stanford
  Heuristic Programming Project}.
\newblock Addison-Wesley Publishing Company, 1984.

\bibitem[\protect\citeauthoryear{Bunt}{1990}]{Bunt}
H.~C. Bunt.
\newblock {Modular Incremental Modelling of Belief and Intention}.
\newblock In {\em Proceedings of the Second International Workshop on User
  Modeling}, 1990.

\bibitem[\protect\citeauthoryear{Cahour}{1990}]{Cahour-90-Montreal}
B\'eatrice Cahour.
\newblock {Competence Modelling in Consultation Dialogs}.
\newblock In L.~Berlinguet and D.~Berthelette, editors, {\em Proceedings of the
  International Congress, Work With Dispay Units' 89}, Montreal, Canada,
  September 1990. North Holland, Amsterdam.

\bibitem[\protect\citeauthoryear{Cahour}{1988}]{Cahour-thesis}
B\'eatrice Cahour.
\newblock {\em {La Mod\'elisation de l'Interlocuteur: Elaboration du Mod\`ele
  et Effets au Cours de Dialogues de Consultation}}.
\newblock PhD thesis, Universit\'e Paris 8, France, 1991.
\newblock Cognitive psychology PhD.

\bibitem[\protect\citeauthoryear{Carberry}{1988}]{CarberryCL88}
Sandra~M. Carberry.
\newblock {Modeling the User's Plans and Goals}.
\newblock {\em Computational Linguistics}, 14(3):23--37, September 1988.

\bibitem[\protect\citeauthoryear{Carbonell}{1970}]{CarbonellScholar}
J.~R. Carbonell.
\newblock {AI in CAI: An Artificial Intelligence Approach to Computer-Aided
  Instruction}.
\newblock {\em IEEE Transactions on Man-Machine Systems}, 11:190--202, 1970.

\bibitem[\protect\citeauthoryear{Carr and Goldstein}{1977}]{Carr-Goldstein}
B.~Carr and I.~Goldstein.
\newblock {Overlays: A Theory of Modelling for Computed Aided Instruction}.
\newblock AI Memo 406, 1977.

\bibitem[\protect\citeauthoryear{Cawsey}{(in press)}]{CawseyIJMMS}
Alison Cawsey.
\newblock {Planning Interactive Explanations}.
\newblock {\em International Journal of Man-Machine Studies}, in press.
                                                               
\bibitem[\protect\citeauthoryear{Chandrasekaran and Swartout}{1991}]{chandra-swartout}
B.~Chandrasekaran and William Swartout.
\newblock {Explanations in Knowledge Systems: The Role of Explicit
  Representation of Design Knowledge}.
\newblock {\em IEEE Expert}, 6(3):47--50, June 1991.

\bibitem[\protect\citeauthoryear{Chappel and Cahour}{1991}]{MMI2-d3}
Helen Chappel and B\'eatrice Cahour.
\newblock {User Modeling for Multi-Modal Co-Operative Dialogue with KBS}.
\newblock Deliverable D3, Esprit Project P2474, 1991.

\bibitem[\protect\citeauthoryear{Chin}{1987}]{ChinThesis}
David~N. Chin.
\newblock {\em Intelligent Agents as a Basis for Natural Language Interfaces}.
\newblock PhD thesis, University of California at Berkeley, 1987.

\bibitem[\protect\citeauthoryear{Chin}{1989}]{Chin88-book}
David~N. Chin.
\newblock {KNOME}: {M}odeling {W}hat the {U}ser {K}nows in {UC}.
\newblock In Alfred Kobsa and Wolfgang Wahlster, editors, {\em User Models in
  Dialog Systems}. Springer-Verlag, Symbolic Computation Series, Berlin
  Heidelberg New York Tokyo, 1989.

\bibitem[\protect\citeauthoryear{Cohen and Jones}{1989}]{Cohen-Jones88-book}
Robin Cohen and Marlene Jones.
\newblock {Incorporating User Models into Expert Systems for Educational
  Diagnosis}.
\newblock In Alfred Kobsa and Wolfgang Wahlster, editors, {\em User Models in
  Dialog Systems}, pages 35 -- 51. Springer-Verlag, Symbolic Computation
  Series, Berlin Heidelberg New York Tokyo, 1989.

\bibitem[\protect\citeauthoryear{Falzon}{1987}]{Falzon87}
Pierre Falzon.
\newblock {Les Dialogues de Diagnostic: L'\'evaluation des Connaissances de
  l'Interlocuteur}.
\newblock Technical Report 747, INRIA, Rocquencourt, France, 1987.

\bibitem[\protect\citeauthoryear{Finin et al.}{1986}]{FininJoshiWebber}
Timothy~W. Finin, Aravind~K. Joshi, and Bonnie~Lynn Webber.
\newblock {Natural Language Interactions with Artificial Experts}.
\newblock {\em Proceedings of the IEEE}, 74(7), July 1986.

\end{thebibliography}
\end{article}
\end{document}
